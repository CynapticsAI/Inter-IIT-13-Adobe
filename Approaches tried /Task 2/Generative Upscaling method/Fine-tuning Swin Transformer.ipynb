{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"22-24/Final\", split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, Swin2SRForImageSuperResolution\n",
    "import datasets  # Hugging Face datasets library\n",
    "import io\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "# Define custom dataset class\n",
    "class ImageSuperResolutionDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, transform_input, transform_target):\n",
    "        self.dataset = hf_dataset\n",
    "        self.transform_input = transform_input\n",
    "        self.transform_target = transform_target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        image = data  # Replace \"image_path\" with your dataset's image key\n",
    "        input_image = self.transform_input(image)\n",
    "        target_image = self.transform_target(image)\n",
    "        return input_image, target_image\n",
    "\n",
    "# Custom transform to add JPEG encoding\n",
    "class JpegEncodingOnly:\n",
    "    def __init__(self, quality=85):  # Default JPEG quality is 75\n",
    "        self.quality = quality\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Encode image to JPEG\n",
    "        buffer = io.BytesIO()\n",
    "        img.save(buffer, format=\"JPEG\", quality=self.quality)\n",
    "        buffer.seek(0)\n",
    "        img = Image.open(buffer)  # Return JPEG-encoded bytes\n",
    "        img.load()\n",
    "        return img\n",
    "\n",
    "# Transformation pipeline\n",
    "transform_input = transforms.Compose([\n",
    "    JpegEncodingOnly(),\n",
    "    transforms.Resize((32, 32)),           # Resize to 32x32 (Optional if not decoding back)\n",
    "    transforms.ToTensor(),                 # Convert to tensor (Not valid on byte stream)\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize (Not valid on byte stream)\n",
    "])\n",
    "\n",
    "transform_target = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "hf_dataset = dataset[\"image\"] \n",
    "custom_dataset = ImageSuperResolutionDataset(hf_dataset, transform_input, transform_target)\n",
    "dataloader = DataLoader(custom_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Load model\n",
    "processor = AutoImageProcessor.from_pretrained(\"caidas/swin2SR-realworld-sr-x4-64-bsrgan-psnr\")\n",
    "model = Swin2SRForImageSuperResolution.from_pretrained(\"caidas/swin2SR-realworld-sr-x4-64-bsrgan-psnr\")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = torch.nn.DataParallel(model)  # Wrap the model\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with tqdm(dataloader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{epochs}\") as pbar:\n",
    "        for input_image, target_image in pbar:\n",
    "            input_image = input_image.to(device)\n",
    "            target_image = target_image.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(pixel_values=input_image)\n",
    "            loss = criterion(outputs.reconstruction, target_image)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "           \n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss/len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Inference function\n",
    "def infer(input_image_path, model, processor, transform_input, device=\"cuda\"):\n",
    "    \n",
    "    input_image = Image.open(input_image_path).convert(\"RGB\")\n",
    "    input_image = transform_input(input_image).unsqueeze(0).to(device)  \n",
    "\n",
    "    \n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values=input_image)\n",
    "        output_image = outputs.reconstruction.squeeze().cpu().clamp(0, 1)  \n",
    "\n",
    "    # Convert tensor to PIL Image for visualization\n",
    "    output_image_pil = transforms.ToPILImage()(output_image)\n",
    "    return output_image_pil\n",
    "\n",
    "# Load a sample image for inference\n",
    "input_image_path = \" \"  # Provide the path to your test image\n",
    "output_image = infer(input_image_path, model, processor, transform_input)\n",
    "\n",
    "# Display the input and output images\n",
    "input_image = Image.open(input_image_path).convert(\"RGB\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Input Image\")\n",
    "plt.imshow(input_image)\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Output Image (Super-Resolution)\")\n",
    "plt.imshow(output_image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Swin2SRForImageSuperResolution, AutoImageProcessor\n",
    "\n",
    "# Save model and processor to Hugging Face Hub\n",
    "def save_model_to_huggingface(model, processor, repo_name=\"swin2SR-custom-model\"):\n",
    "    \n",
    "    model.save_pretrained(f\"./{repo_name}\")\n",
    "    processor.save_pretrained(f\"./{repo_name}\")\n",
    "\n",
    "    \n",
    "    model.push_to_hub(repo_name)\n",
    "    processor.push_to_hub(repo_name)\n",
    "\n",
    "\n",
    "repo_name = \" \" \n",
    "\n",
    "# Save model and processor\n",
    "save_model_to_huggingface(model, processor, repo_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pathway",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
